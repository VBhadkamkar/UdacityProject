{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25866b1a79284366abbb1a7eccc2c851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357603c0c5104df88e6cbf2f44c98f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7130d8a7cb244774b282ba16bc6eb8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2885d1583e4d04ae981f3b4a0d03e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339d89b0af344f2f81cb9b62178a3061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e072b3b34c84d2ba9df5f1de2c79aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels = 2, id2label = {0 : 'Negative', 1 : \"Positive\" }, label2id = {'Negative' : 0 , \"Positive\" : 1 })\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ffaf185ae248609624fa7d39cd918b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 699k/699k [00:00<00:00, 3.28MB/s]\n",
      "Downloading data: 100%|██████████| 90.0k/90.0k [00:00<00:00, 352kB/s]\n",
      "Downloading data: 100%|██████████| 92.2k/92.2k [00:00<00:00, 425kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4744ab8c39c4b0a8243ade653cf94bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d83ed45622342f4a0c1be421863bad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb6dab126704ea99da5c3934e9b7ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 6824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1706\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\", split = \"train\").train_test_split(test_size = 0.2, shuffle = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674fc945cc5c458285814cd968581bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84bacc306bc4ddaad8f190423b2ca3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding = True, truncation = True)\n",
    "train_dataset = dataset['train'].map(tokenize, batched = True)\n",
    "test_dataset = dataset['test'].map(tokenize, batched = True)\n",
    "#train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "    return {\"accuracy\" : (predictions == labels).mean()}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 4,\n",
    "    per_device_eval_batch_size = 4,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay = 0.01,\n",
    "    save_strategy = \"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b32480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='427' max='427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [427/427 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 8.170622825622559,\n",
       " 'eval_accuracy': 0.5035169988276671,\n",
       " 'eval_runtime': 9.1456,\n",
       " 'eval_samples_per_second': 186.538,\n",
       " 'eval_steps_per_second': 46.689}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 150,528 || all params: 124,590,336 || trainable%: 0.1208183594592762\n"
     ]
    }
   ],
   "source": [
    "#PEFT Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels = 2, id2label = {0 : 'Negative', 1 : \"Positive\" }, label2id = {'Negative' : 0 , \"Positive\" : 1 })\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForSequenceClassification\n",
    "peft_config = LoraConfig(\n",
    "    task_type = \"SEQ_CLS\",\n",
    "    inference_mode = False,\n",
    "    r = 4,\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1,\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions,labels = eval_pred\n",
    "  predictions = np.argmax(predictions, axis = 1)\n",
    "  return {\"accuracy\" : (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir = \"./results/peft_model\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_steps = 10,\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 4,\n",
    "    per_device_eval_batch_size = 4,\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    load_best_model_at_end = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8530' max='8530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8530/8530 08:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.460512</td>\n",
       "      <td>0.803048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.499121</td>\n",
       "      <td>0.832356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>0.488316</td>\n",
       "      <td>0.844666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.483491</td>\n",
       "      <td>0.849941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.507082</td>\n",
       "      <td>0.849941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8530, training_loss=0.5556017107309518, metrics={'train_runtime': 537.2757, 'train_samples_per_second': 63.506, 'train_steps_per_second': 15.876, 'total_flos': 1243403185102848.0, 'train_loss': 0.5556017107309518, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer = Trainer(\n",
    "    model = model,\n",
    "    args = peft_training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='427' max='427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [427/427 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4605118930339813,\n",
       " 'eval_accuracy': 0.8030480656506448,\n",
       " 'eval_runtime': 10.1647,\n",
       " 'eval_samples_per_second': 167.836,\n",
       " 'eval_steps_per_second': 42.008,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_eval_results = peft_trainer.evaluate()\n",
    "peft_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ba10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"model/peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Performing Inference with PEFT Model\n",
    "import torch\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "inference_model = AutoPeftModelForSequenceClassification.from_pretrained('model/peft_model', id2label = {0 : 'Negative', 1 : \"Positive\" }, label2id = {'Negative' : 0 , \"Positive\" : 1 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1706' max='1706' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1706/1706 01:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.487000</td>\n",
       "      <td>0.428019</td>\n",
       "      <td>0.832356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1706, training_loss=0.47871679326154704, metrics={'train_runtime': 107.4472, 'train_samples_per_second': 63.51, 'train_steps_per_second': 15.878, 'total_flos': 248582888091648.0, 'train_loss': 0.47871679326154704, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_args = TrainingArguments(\n",
    "    output_dir=\"./results/peft_model_inference\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "tuned_trainer = Trainer(\n",
    "    model = peft_model,\n",
    "    args = inference_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "tuned_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Result on Pretrained Model: {'eval_loss': 8.170622825622559, 'eval_accuracy': 0.5035169988276671, 'eval_runtime': 9.1456, 'eval_samples_per_second': 186.538, 'eval_steps_per_second': 46.689}\n",
      "Final Result on LoRa Model: {'eval_loss': 0.4605118930339813, 'eval_accuracy': 0.8030480656506448, 'eval_runtime': 10.1647, 'eval_samples_per_second': 167.836, 'eval_steps_per_second': 42.008, 'epoch': 5.0}\n",
      "Final Result on Tuned Model: {'eval_loss': 0.4280189573764801, 'eval_accuracy': 0.8323563892145369, 'eval_runtime': 6.7331, 'eval_samples_per_second': 253.375, 'eval_steps_per_second': 8.02, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "tuned_result = tuned_trainer.evaluate()\n",
    "print(\"Final Result on Pretrained Model:\", eval_results)\n",
    "print(\"Final Result on LoRa Model:\", peft_eval_results)\n",
    "print(\"Final Result on Tuned Model:\", tuned_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
